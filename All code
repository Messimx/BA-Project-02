###################### Load library and csv files  ########################

#libraries
library(randomForest)
library(pROC)
library(lattice)
library(e1071)
library(caret)
library(DiagrammeR)
library(party)
library(xgboost)
library(rpart)
library(rattle)
library(rpart.plot)
library(dataQualityR)
library(ggplot2)
library(lubridate)
library(stringr)
library(dplyr)
library(magrittr)

#loading the files
options(scipen = 999)
countries="C:/Users/Messi/Desktop/Classes/BusinessAnalytics/Project/Project02/countries.csv"
age_gender="C:/Users/Messi/Desktop/Classes/BusinessAnalytics/Project/Project02/age_gender_bkts.csv"
sessions_df="C:/Users/Messi/Desktop/Classes/BusinessAnalytics/Project/Project02/sessions.csv"
test_user="C:/Users/Messi/Desktop/Classes/BusinessAnalytics/Project/Project02/test_users.csv"
train_users="C:/Users/Messi/Desktop/Classes/BusinessAnalytics/Project/Project02/train_users_2.csv"
countries_df=read.csv(countries,stringsAsFactors = F,header = T)
age_gender_df=read.csv(age_gender,stringsAsFactors = F,header = T)
sessions_df=read.csv(sessions_df,stringsAsFactors = F,header = T)
test_user_df=read.csv(test_user,stringsAsFactors = F,header = T)
train_users_df=read.csv(train_users,stringsAsFactors = F,header = T)


###################### Clean and filter data  ########################

#setting the lables right
label_train = train_users_df[, c('id', 'country_destination')]
label_test = test_user_df[, c('id')]
names(sessions_df)[1] <- "id"
#adding country column in test before merging
test_user_df$country_destination = NA
#clean date
train_users_df$date_account_created=as.Date(train_users_df$date_account_created,"%Y-%m-%d")
test_user_df$date_account_created=as.Date(test_user_df$date_account_created,"%Y-%m-%d")
#clean timestamp
train_users_df$timestamp_first_active=(ymd_hms(train_users_df$timestamp_first_active,locale = Sys.getlocale("LC_TIME")))
test_user_df$timestamp_first_active=(ymd_hms(test_user_df$timestamp_first_active,locale = Sys.getlocale("LC_TIME")))
#dropping values before 2013
train_subset <- subset(train_users_df, as.integer(substr(date_account_created,1,4)) >= 2013)
#merging
new_df=rbind(train_subset,test_user_df)
#remove date of first booking
new_df<-new_df[-4]
#age cleaning
new_df<- new_df%>%
  dplyr::mutate(
    age = ifelse(age >= 1920, 2015 - age, age),
    age = ifelse(age < 14 | age > 100, -1, age))

new_df$age[is.na(new_df$age)] <- median(new_df$age, na.rm=TRUE)

new_df<-new_df[!new_df$age<16,]
#age bucketing
new_df<- new_df%>%
  dplyr::mutate(
    age_bucket = cut(age, breaks = c(1, 4, 9, 14, 19, 24,
                                     29, 34, 39, 44, 49, 54,
                                     59, 64, 69, 74, 79, 84,
                                     89, 94, 99, 105)),
    age_bucket = plyr::mapvalues(age_bucket,
                                 from=c("(1,4]", "(4,9]", "(9,14]", "(14,19]",
                                        "(19,24]", "(24,29]", "(29,34]", "(34,39]",
                                        "(39,44]", "(44,49]", "(49,54]", "(54,59]",
                                        "(59,64]", "(64,69]", "(69,74]", "(74,79]",
                                        "(79,84]", "(84,89]", "(89,94]", "(94,99]", "(99,105]"),
                                 to=c("0-4", "5-9", "10-14", "15-19",
                                      "20-24", "25-29", "30-34", "35-39",
                                      "40-44", "45-49", "50-54", "55-59",
                                      "60-64", "65-69", "70-74", "75-79",
                                      "80-84", "85-89", "90-94", "95-99", "100+")))
#removing all NA country destination rows
new_df=new_df[!is.na(new_df$country_destination),]

#dataquality
num.file <- paste(tempdir(), "/dq_num.csv", sep= "")
cat.file <- paste(tempdir(), "/dq_cat.csv", sep= "")
checkDataQuality(data= new_df, out.file.num= num.file, out.file.cat= cat.file)
df_num=read.csv(num.file)
df_cat=read.csv(cat.file)
#session
str(sessions_df)
#checking for NA values 
sum(is.na(sessions_df$secs_elapsed))
#inputting session NA values
sessions_df$secs_elapsed[is.na(sessions_df$secs_elapsed)] <- mean(na.omit(sessions_df$secs_elapsed))
#merging
session_unique <- sessions_df %>% group_by(id) %>% summarize(totalActions = length(action), 
                                                             uniqueActions = length(unique(action)),
                                                             uniqueAction_type=length(unique(action_type)),
                                                             uniqueAction_detail=length(unique(action_detail)),   
                                                             freqAction_detail=names(which.max(table(action_detail))),
                                                             device = names(which.max(table(device_type))),
                                                             time_sec = sum(secs_elapsed))
#merging sessions data and with train data
new_df=merge(new_df,session_unique,"id")

#dataquality
num.file <- paste(tempdir(), "/dq_num.csv", sep= "")
cat.file <- paste(tempdir(), "/dq_cat.csv", sep= "")
checkDataQuality(data= new_df, out.file.num= num.file, out.file.cat= cat.file)
df_num=read.csv(num.file)
df_cat=read.csv(cat.file)

#replacing missing values
new_df$freqAction_detail[new_df$freqAction_detail==""]="-unkown-"
new_df$first_affiliate_tracked[new_df$first_affiliate_tracked==""]="-unkown-"
new_df_stored<-new_df

###################### Build model  ########################

################ Decision Tree #############
###### First layer: Yes:NDF/NO:non_NDF
new_df<-new_df_stored
new_df$NDF<-ifelse(new_df$country_destination=='NDF',as.logical(1),as.logical(0))


###### Convert character columns to numeric
int_num<-function(x){
  x<-as.numeric(x)
}

chr_num<-function(x){
  x<-as.factor(x)
  x<-as.numeric(x)
}

new_df[,c('age','signup_flow','totalActions', 'uniqueActions','uniqueAction_type','uniqueAction_detail')]<-sapply(new_df[,c('age','signup_flow','totalActions', 'uniqueActions','uniqueAction_type','uniqueAction_detail')],int_num)
new_df[,c('date_account_created','timestamp_first_active','gender','signup_method','language','affiliate_channel','affiliate_provider',
          "first_affiliate_tracked",'signup_app','first_device_type','first_browser','age_bucket',
          'freqAction_detail','device')]<-sapply(
            new_df[,c('date_account_created','timestamp_first_active','gender','signup_method','language','affiliate_channel','affiliate_provider',
                      "first_affiliate_tracked",'signup_app','first_device_type','first_browser','age_bucket',
                      'freqAction_detail','device')], chr_num
          )

###### Split the data set
set.seed(1234)
#split ratio is (train.csv : test.csv)
split<-(nrow(train_users_df)/(nrow(test_user_df)+nrow(train_users_df)))
trn_index<-sample(1:nrow(new_df),(split)*nrow(new_df))  
trn<-new_df[trn_index, ]
tst<-new_df[-trn_index,]

###### Use Decision Tree method to fit the model
dt<-rpart(NDF~uniqueAction_type+
            age+
            freqAction_detail+
            signup_method+
            time_sec+
            totalActions+
            timestamp_first_active+
            uniqueActions+
            first_browser+
            uniqueAction_detail+
            affiliate_channel+
            language+
            first_affiliate_tracked+
            device+
            date_account_created+
            signup_app+
            first_device_type+
            signup_flow+
            affiliate_provider, data = trn, method = "class")
printcp(dt)
fancyRpartPlot(dt)

tst$pre_NDF <- predict(dt, tst, type = "class")
tst$NDF_result<-ifelse(tst$NDF==tst$pre_NDF,1,0)
tb_pre<-tst[,c('NDF','pre_NDF')]
conclusion<-table(tb_pre)
conclusion

###### Accuracy of the first layer's model
accuracy<-(conclusion[1]+conclusion[4])/sum(conclusion)
accuracy
auc(as.numeric(tst$NDF),as.numeric(tst$pre_NDF))

###### Second layer: Yes:US/NO:non_US
trn$US<-ifelse(trn$country_destination=='US',as.logical(1),as.logical(0))
tst$US<-ifelse(tst$country_destination=='US',as.logical(1),as.logical(0))
tst$pre_US<-ifelse(tst$pre_NDF==as.logical(1),as.logical(0),NA)
tst_US<-subset(tst,pre_NDF==as.logical(0))

###### Use xgboost method to fit the model
dt<-rpart(US~uniqueAction_type+
            age+
            freqAction_detail+
            signup_method+
            time_sec+
            totalActions+
            timestamp_first_active+
            uniqueActions+
            first_browser+
            uniqueAction_detail+
            affiliate_channel+
            language+
            first_affiliate_tracked+
            device+
            date_account_created+
            signup_app+
            first_device_type+
            signup_flow+
            affiliate_provider, data = trn, method = "class")
printcp(dt)
fancyRpartPlot(dt)

tst_US$pre_US <- predict(dt, tst_US, type = "class")
tb_pre<-tst_US[,c('US','pre_US')]
conclusion<-table(tb_pre)
conclusion

###### Accuracy of the second layer's model
accuracy<-(conclusion[1]+conclusion[4])/sum(conclusion)
accuracy
auc(as.numeric(tst_US$US),as.numeric(tst_US$pre_US))

###### Total accuracy of above two layer's model
j=1
for(i in 1:nrow(tst)){
  if(tst$id[i]==tst_US$id[j]){
    tst$pre_US[i]<-tst_US$pre_US[j]
    j<-j+1
  }
}

tst$US_result<-ifelse(tst$US==tst$pre_US,1,0)
total_accuracy<-nrow(subset(tst,(US_result==1)&(NDF_result==1)))/nrow(tst)
total_accuracy

################ Xgboost #############
###### First layer: Yes:NDF/NO:non_NDF
new_df<-new_df_stored
new_df$NDF<-ifelse(new_df$country_destination=='NDF',as.logical(1),as.logical(0))


###### Convert character columns to numeric
int_num<-function(x){
  x<-as.numeric(x)
}

chr_num<-function(x){
  x<-as.factor(x)
  x<-as.numeric(x)
}

new_df[,c('age','signup_flow','totalActions', 'uniqueActions','uniqueAction_type','uniqueAction_detail')]<-sapply(new_df[,c('age','signup_flow','totalActions', 'uniqueActions','uniqueAction_type','uniqueAction_detail')],int_num)
new_df[,c('date_account_created','timestamp_first_active','gender','signup_method','language','affiliate_channel','affiliate_provider',
          "first_affiliate_tracked",'signup_app','first_device_type','first_browser','age_bucket',
          'freqAction_detail','device')]<-sapply(
            new_df[,c('date_account_created','timestamp_first_active','gender','signup_method','language','affiliate_channel','affiliate_provider',
                      "first_affiliate_tracked",'signup_app','first_device_type','first_browser','age_bucket',
                      'freqAction_detail','device')], chr_num
          )

###### Split the data set
set.seed(1234)
#split ratio is (train.csv : test.csv)
split<-(nrow(train_users_df)/(nrow(test_user_df)+nrow(train_users_df)))
trn_index<-sample(1:nrow(new_df),(split)*nrow(new_df))  
trn<-new_df[trn_index, ]
tst<-new_df[-trn_index,]

###### Use xgboost method to fit the model
X = as.matrix(trn[,-c(1,15,24)]) #remove unnumeric columns
y = trn$NDF
dtrain <- xgb.DMatrix(data = X, label=y)
bst <- xgb.train(data = dtrain,max.depth = 4, eta = 0.1, nthread = 2, nround = 300, objective = "binary:logistic", verbose = 1)

tst$pre_NDF = ifelse(predict(bst, data.matrix(tst[,-c(1,15,24)]))>0.5,as.logical(1),as.logical(0))
tst$NDF_result<-ifelse(tst$NDF==tst$pre_NDF,1,0)
tb_pre<-tst[,c('NDF','pre_NDF')]
conclusion<-table(tb_pre)
conclusion

###### Accuracy of the first layer's model
accuracy<-(conclusion[1]+conclusion[4])/sum(conclusion)
accuracy
auc(as.numeric(tst$NDF),as.numeric(tst$pre_NDF))

###### Importance rank of the parameters
importance <- xgb.importance(feature_names =colnames(trn[,-c(1,15,24)]), model = bst)
xgb.plot.importance(importance_matrix = importance)


###### Second layer: Yes:US/NO:non_US
trn$US<-ifelse(trn$country_destination=='US',as.logical(1),as.logical(0))
tst$US<-ifelse(tst$country_destination=='US',as.logical(1),as.logical(0))
tst$pre_US<-ifelse(tst$pre_NDF==as.logical(1),as.logical(0),NA)
tst_US<-subset(tst,pre_NDF==as.logical(0))

###### Use xgboost method to fit the model
X = as.matrix(trn[,-c(1,15,24,25)]) #remove unnumeric columns
y = trn$US
dtrain <- xgb.DMatrix(data = X, label=y)
bst <- xgb.train(data = dtrain,max.depth = 4, eta = 0.1, nthread = 2, nround = 300, objective = "binary:logistic", verbose = 1)

tst_US$pre_US = ifelse(predict(bst, data.matrix(tst_US[,-c(1,15,24,25)]))>0.5,as.logical(1),as.logical(0))
tb_pre<-tst_US[,c('US','pre_US')]
conclusion<-table(tb_pre)
conclusion

###### Accuracy of the second layer's model
accuracy<-(conclusion[1]+conclusion[4])/sum(conclusion)
accuracy
auc(as.numeric(tst_US$US),as.numeric(tst_US$pre_US))

###### Importance rank of the parameters
importance <- xgb.importance(feature_names =colnames(trn[,-c(1,15,24,25)]), model = bst)
xgb.plot.importance(importance_matrix = importance)

###### Total accuracy of above two layer's model
j=1
for(i in 1:nrow(tst)){
  if(tst$id[i]==tst_US$id[j]){
    tst$pre_US[i]<-tst_US$pre_US[j]
    j<-j+1
  }
}

tst$US_result<-ifelse(tst$US==tst$pre_US,1,0)
total_accuracy<-nrow(subset(tst,(US_result==1)&(NDF_result==1)))/nrow(tst)
total_accuracy



######## Improvement Method (also using xgboost) ######################
new_df<-new_df_stored
set.seed(0101)
split=(0.7)
index=sample(1:nrow(new_df),(split)*nrow(new_df))
testd <- new_df[-index,]
#testd=testd[-grep('country_destination', colnames(testd))] 
traind <- new_df[index,]
labels = traind['country_destination']
#labels_t = testd['country_destination'] ###

#XGBOOST
#dummy variables creation
ohe_feats = c('gender', 'signup_method', 'signup_flow', 'language', 'affiliate_channel', 'affiliate_provider', 'first_affiliate_tracked', 'signup_app', 'first_device_type', 'first_browser','age_bucket','freqAction_detail','device')
dummies <- dummyVars(~ gender + signup_method + signup_flow + language + affiliate_channel + affiliate_provider + first_affiliate_tracked + signup_app + first_device_type + first_browser+age_bucket+freqAction_detail+device, data = new_df)
df_all_ohe <- as.data.frame(predict(dummies, newdata = new_df))
df_all_combined <- cbind(new_df[,-c(which(colnames(new_df) %in% ohe_feats))],df_all_ohe)

X = df_all_combined[df_all_combined$id %in% traind$id,]
y <- recode(labels$country_destination,"'NDF'=0; 'US'=1; 'other'=2; 'FR'=3; 'CA'=4; 'GB'=5; 'ES'=6; 'IT'=7; 'PT'=8; 'NL'=9; 'DE'=10; 'AU'=11")
X_test = df_all_combined[df_all_combined$id %in% testd$id,]
#cross validation
params <- list(booster = "gbtree", objective="multi:softprob", 
               eta=0.3, gamma=0, max_depth=6, min_child_weight=1, subsample=1, colsample_bytree=1) ###CN
xgbcv <- xgb.cv( params = params, data = data.matrix(X), nrounds = 50, nfold = 5, label=y,
                 showsd = T, stratified = T, print_every_n = 10, early_stop_rounds = 20, 
                 num_class =12,maximize = F)
#trainmodel
xgb <- xgboost(data = data.matrix(X), 
               label = y, 
               eta = 0.3, #shrinkage rate to control overfitting through conservative approach
               max_depth = 10, #how many levels in the tree
               nround=10, #controls the maximum number of iterations.it is similar to the number of trees to grow(tuned using CV)
               subsample = 0.5, #how much of the data to use for each tree
               colsample_bytree = 0.5, #how many variables to consider for each tree
               seed = 1,
               eval_metric = "mlogloss",
               objective = "multi:softprob",
               num_class = 12,
               nthread = 4,
               missing=NA
)

## Anayse and visualize xgboost
model <- xgb.dump(xgb, with_stats = T)
model[1:10]
names <- dimnames(data.matrix(X))[[2]]
importance_matrix <- xgb.importance(names, model = xgb)

xgb.plot.importance(importance_matrix[1:20,])
# predict values in test set
y_pred <- predict(xgb, data.matrix(X_test),missing=NA)

preds <- as.data.frame(matrix(y_pred, nrow=12))
rownames(preds) <- c('NDF','US','other','FR','CA','GB','ES','IT','PT','NL','DE','AU')
preds_top5 <- as.vector(apply(preds, 2, function(x) names(sort(x)[12:8])))

ids <- NULL
for (i in 1:NROW(X_test)) {
  idx <- X_test$id[i]
  ids <- append(ids, rep(idx,5))
}
results <- NULL
results$id <- ids
results$country <- preds_top5
# generate result file
results <- as.data.frame(results)

##############
library(DiagrammeR)
xgb.plot.tree(feature_names = names, model = xgb, n_first_tree = 20)
######
num.class=length(y)
pred.cv = matrix(model_xgb$evaluation_log, nrow=length(model_xgb$evaluation_log)/num.class, ncol=num.class)
pred.cv = max.col(pred.cv, "last")
