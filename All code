###################### Load library and csv files  ########################

#libraries
library(lattice)
library(e1071)
library(caret)
library(DiagrammeR)
library(party)
library(xgboost)
library(rpart)
library(rattle)
library(rpart.plot)
library(dataQualityR)
library(ggplot2)
library(lubridate)
library(stringr)
library(dplyr)
library(magrittr)
t1=Sys.time()
#loading the files
options(scipen = 999)
countries="/Users/sujay/Desktop/NYU/BA Assignments/Airbnb Data/countries.csv"
age_gender="/Users/sujay/Desktop/NYU/BA Assignments/Airbnb Data/age_gender_bkts.csv"
sessions_df="/Users/sujay/Desktop/NYU/BA Assignments/Airbnb Data/sessions.csv"
test_user="/Users/sujay/Desktop/NYU/BA Assignments/Airbnb Data/test_users.csv"
train_users="/Users/sujay/Desktop/NYU/BA Assignments/Airbnb Data/train_users_2.csv"
countries_df=read.csv(countries,stringsAsFactors = F,header = T)
age_gender_df=read.csv(age_gender,stringsAsFactors = F,header = T)
sessions_df=read.csv(sessions_df,stringsAsFactors = F,header = T)
test_user_df=read.csv(test_user,stringsAsFactors = F,header = T)
train_users_df=read.csv(train_users,stringsAsFactors = F,header = T)


###################### Clean and filter data  ########################

#setting the lables right
label_train = train_users_df[, c('id', 'country_destination')]
label_test = test_user_df[, c('id')]
names(sessions_df)[1] <- "id"
#adding country column in test before merging
test_user_df$country_destination = NA
#clean date
train_users_df$date_account_created=as.Date(train_users_df$date_account_created,"%Y-%m-%d")
test_user_df$date_account_created=as.Date(test_user_df$date_account_created,"%Y-%m-%d")
#clean timestamp
train_users_df$timestamp_first_active=(ymd_hms(train_users_df$timestamp_first_active,locale = Sys.getlocale("LC_TIME")))
test_user_df$timestamp_first_active=(ymd_hms(test_user_df$timestamp_first_active,locale = Sys.getlocale("LC_TIME")))
#dropping values before 2013
train_subset <- subset(train_users_df, as.integer(substr(date_account_created,1,4)) >= 2013)
#merging
new_df=rbind(train_subset,test_user_df)
#remove date of first booking
new_df<-new_df[-4]
#age cleaning
new_df<- new_df%>%
  dplyr::mutate(
    age = ifelse(age >= 1920, 2015 - age, age),
    age = ifelse(age < 14 | age > 100, -1, age))

new_df$age[is.na(new_df$age)] <- median(new_df$age, na.rm=TRUE)

new_df<-new_df[!new_df$age<16,]
#age bucketing
new_df<- new_df%>%
  dplyr::mutate(
    age_bucket = cut(age, breaks = c(1, 4, 9, 14, 19, 24,
                                     29, 34, 39, 44, 49, 54,
                                     59, 64, 69, 74, 79, 84,
                                     89, 94, 99, 105)),
    age_bucket = plyr::mapvalues(age_bucket,
                                 from=c("(1,4]", "(4,9]", "(9,14]", "(14,19]",
                                        "(19,24]", "(24,29]", "(29,34]", "(34,39]",
                                        "(39,44]", "(44,49]", "(49,54]", "(54,59]",
                                        "(59,64]", "(64,69]", "(69,74]", "(74,79]",
                                        "(79,84]", "(84,89]", "(89,94]", "(94,99]", "(99,105]"),
                                 to=c("0-4", "5-9", "10-14", "15-19",
                                      "20-24", "25-29", "30-34", "35-39",
                                      "40-44", "45-49", "50-54", "55-59",
                                      "60-64", "65-69", "70-74", "75-79",
                                      "80-84", "85-89", "90-94", "95-99", "100+")))
#removing all NA country destination rows
new_df=new_df[!is.na(new_df$country_destination),]

#dataquality
num.file <- paste(tempdir(), "/dq_num.csv", sep= "")
cat.file <- paste(tempdir(), "/dq_cat.csv", sep= "")
checkDataQuality(data= new_df, out.file.num= num.file, out.file.cat= cat.file)
df_num=read.csv(num.file)
df_cat=read.csv(cat.file)
#session
str(sessions_df)
#checking for NA values 
sum(is.na(sessions_df$secs_elapsed))
#inputting session NA values
sessions_df$secs_elapsed[is.na(sessions_df$secs_elapsed)] <- mean(na.omit(sessions_df$secs_elapsed))
#merging
session_unique <- sessions_df %>% group_by(id) %>% summarize(totalActions = length(action), 
                                                             uniqueActions = length(unique(action)),
                                                             uniqueAction_type=length(unique(action_type)),
                                                             uniqueAction_detail=length(unique(action_detail)),   
                                                             freqAction_detail=names(which.max(table(action_detail))),
                                                             device = names(which.max(table(device_type))),
                                                             time_sec = sum(secs_elapsed))
#merging sessions data and with train data
new_df=merge(new_df,session_unique,"id")

#dataquality
num.file <- paste(tempdir(), "/dq_num.csv", sep= "")
cat.file <- paste(tempdir(), "/dq_cat.csv", sep= "")
checkDataQuality(data= new_df, out.file.num= num.file, out.file.cat= cat.file)
df_num=read.csv(num.file)
df_cat=read.csv(cat.file)

#replacing missing values
new_df$freqAction_detail[new_df$freqAction_detail==""]="-unkown-"
new_df$first_affiliate_tracked[new_df$first_affiliate_tracked==""]="-unkown-"


###################### Build model  ########################

###### First layer: Yes:NDF/NO:non_NDF
new_df$NDF<-ifelse(new_df$country_destination=='NDF',as.logical(1),as.logical(0))


###### Convert character columns to numeric
int_num<-function(x){
  x<-as.numeric(x)
}

chr_num<-function(x){
  x<-as.factor(x)
  x<-as.numeric(x)
}

new_df[,c('age','signup_flow','totalActions', 'uniqueActions','uniqueAction_type','uniqueAction_detail')]<-sapply(new_df[,c('age','signup_flow','totalActions', 'uniqueActions','uniqueAction_type','uniqueAction_detail')],int_num)
new_df[,c('date_account_created','gender','signup_method','language','affiliate_channel','affiliate_provider',
          "first_affiliate_tracked",'signup_app','first_device_type','first_browser','age_bucket',
          'freqAction_detail','device')]<-sapply(
            new_df[,c('date_account_created','gender','signup_method','language','affiliate_channel','affiliate_provider',
                      "first_affiliate_tracked",'signup_app','first_device_type','first_browser','age_bucket',
                      'freqAction_detail','device')], chr_num
          )

###### Split the data set
set.seed(1234)
#split ratio is (train.csv : test.csv)
split<-(nrow(train_users_df)/(nrow(test_user_df)+nrow(train_users_df)))
trn_index<-sample(1:nrow(new_df),(split)*nrow(new_df))  
trn<-new_df[trn_index, ]
tst<-new_df[-trn_index,]

###### Use xgboost method to fit the model
X = as.matrix(trn[,-c(1,15,24)]) #remove unnumeric columns
y = trn$NDF
bst <- xgboost(data = X, label = y, max.depth = 4, eta = 0.1, nthread = 2, nround = 300, objective = "binary:logistic", verbose = 1)

tst$pre_NDF = ifelse(predict(bst, data.matrix(tst[,-c(1,15,24)]))>0.5,as.logical(1),as.logical(0))
tst$NDF_result<-ifelse(tst$NDF==tst$pre_NDF,1,0)
tb_pre<-tst[,c('NDF','pre_NDF')]
conclusion<-table(tb_pre)
conclusion

###### Accuracy of the first layer's model
accuracy<-(conclusion[1]+conclusion[4])/sum(conclusion)
accuracy

###### Importance rank of the parameters
importance <- xgb.importance(feature_names =colnames(trn[,-c(1,15,24)]), model = bst)
xgb.plot.importance(importance_matrix = importance)


###### Second layer: Yes:US/NO:non_US
trn$US<-ifelse(trn$country_destination=='US',as.logical(1),as.logical(0))
tst$US<-ifelse(tst$country_destination=='US',as.logical(1),as.logical(0))
tst$pre_US<-ifelse(tst$pre_NDF==as.logical(1),as.logical(0),NA)
tst_US<-subset(tst,pre_NDF=as.logical(0))

###### Use xgboost method to fit the model
X = as.matrix(trn[,-c(1,15,24,25)]) #remove unnumeric columns
y = trn$US
bst <- xgboost(data = X, label = y, max.depth = 4, eta = 0.1, nthread = 2, nround = 300, objective = "binary:logistic", verbose = 1)

tst_US$pre_US = ifelse(predict(bst, data.matrix(tst[,-c(1,15,24,25)]))>0.5,as.logical(1),as.logical(0))
tb_pre<-tst_US[,c('US','pre_US')]
conclusion<-table(tb_pre)
conclusion

###### Accuracy of the second layer's model
accuracy<-(conclusion[1]+conclusion[4])/sum(conclusion)
accuracy

###### Importance rank of the parameters
importance <- xgb.importance(feature_names =colnames(trn[,-c(1,15,24,25)]), model = bst)
xgb.plot.importance(importance_matrix = importance)

###### Total accuracy of above two layer's model
tst$pre_US<-ifelse(is.na(tst$pre_US),tst_US$pre_US,tst$pre_US)
tst$US_result<-ifelse(tst$US==tst$pre_US,1,0)
total_accuracy<-nrow(subset(tst,(US_result==1)&(NDF_result==1)))/nrow(tst)
total_accuracy
